{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Modular Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data \n",
    "option_input_name = 'option_add_Heston.pkl'\n",
    "option = pd.read_pickle(option_input_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "option = option[option.best_bid>1]\n",
    "option = option[option.best_offer>1]\n",
    "option = option.dropna()\n",
    "\n",
    "# extract calls and puts\n",
    "call_option = option[option['cp_flag']=='call'].copy()\n",
    "put_option = option[option['cp_flag']=='put'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create moneyness_class for call option\n",
    "call_option['moneyness_class'] = np.where(call_option['moneyness']>1.05,'itm','atm')\n",
    "call_option['moneyness_class'] = np.where(call_option['moneyness']<0.97,'otm',call_option['moneyness_class'])\n",
    "\n",
    "# create tau_class for call option\n",
    "call_option['tau_class'] = np.where(call_option['tau']>0.2,'longterm','midterm')\n",
    "call_option['tau_class'] = np.where(call_option['tau']<0.1,'shortterm',call_option['tau_class'])\n",
    "\n",
    "# create moneyness_class for put option\n",
    "put_option['moneyness_class'] = np.where(put_option['moneyness']<0.97,'itm','atm')\n",
    "put_option['moneyness_class'] = np.where(put_option['moneyness']>1.05,'otm',put_option['moneyness_class'])\n",
    "\n",
    "# create tau_class for put option\n",
    "put_option['tau_class'] = np.where(put_option['tau']>0.2,'longterm','midterm')\n",
    "put_option['tau_class'] = np.where(put_option['tau']<0.1,'shortterm',put_option['tau_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general function\n",
    "def hybrid_MNN_pricing(option_data,moneyness_class,tau_class,nodes_each_layer,\n",
    "                     activation_functions,inverse_transform,output_df,stochastic_model=None):\n",
    "    data = option_data[(option_data['moneyness_class']==moneyness_class) & (option_data['tau_class']==tau_class)]\n",
    "    years_performance = []\n",
    "    years_data = pd.DataFrame()\n",
    "    years = list(data.index.year.unique()) \n",
    "    years.remove(2016) # too few samples\n",
    "    yearly_data = [data[data.index.year == i] for i in years]\n",
    "    for yearwise_data in yearly_data: #different years\n",
    "        yearwise_data_train = yearwise_data.iloc[:int(len(yearwise_data)/2),:]\n",
    "        yearwise_data_validation = yearwise_data.iloc[int(len(yearwise_data)/2):int(len(yearwise_data)*3/4),:]\n",
    "        yearwise_data_test= yearwise_data.iloc[int(len(yearwise_data)*3/4):,:]\n",
    "        \n",
    "        # build NN model:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(nodes_each_layer[0],activation = activation_functions[0],input_shape = (2,)))\n",
    "        model.add(Dropout(0.2)) \n",
    "        model.add(Dense(nodes_each_layer[1],activation = activation_functions[1]))\n",
    "        model.add(Dropout(0.2)) \n",
    "        model.add(Dense(nodes_each_layer[2],activation = activation_functions[2]))\n",
    "        model.compile(loss='mean_squared_error',optimizer=RMSprop(),metrics=['mae'])\n",
    "         \n",
    "        # normalize\n",
    "        sc1 = StandardScaler() # fit training features\n",
    "        sc2 = StandardScaler() # fit training target, inverse transform for test prediction\n",
    "        sc3 = StandardScaler() # fit validation features and/or target (shared without reuse conflict)\n",
    "        print('----------year = ',yearwise_data.index.year[0],'-----------')\n",
    "        \n",
    "        # early stopping\n",
    "        es = keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0,patience=3,verbose=2, mode='auto') \n",
    "        \n",
    "        yearwise_data_train['minus']=yearwise_data_train['last']-yearwise_data_train[stochastic_model] \n",
    "        yearwise_data_validation['minus']=yearwise_data_validation['last']-yearwise_data_validation[stochastic_model]\n",
    "        \n",
    "        # fit\n",
    "        if inverse_transform == False: \n",
    "            history = model.fit(sc1.fit_transform(yearwise_data_train[['moneyness','tau']]),yearwise_data_train['minus'],batch_size=50,epochs=100,verbose=2,validation_data=(sc3.fit_transform(yearwise_data_validation[['moneyness','tau']]),yearwise_data_validation['minus']),callbacks=[es]) \n",
    "            \n",
    "            # percentage mean-squared-error:    \n",
    "            prediction = model.predict(sc1.transform(yearwise_data_test[['moneyness','tau']]))\n",
    "            yearwise_data_test_copy = yearwise_data_test.copy()\n",
    "            yearwise_data_test_copy[stochastic_model+'_MNN_price'] = prediction  # inverse \n",
    "            yearwise_data_test_copy[stochastic_model+'_MNN_price']=yearwise_data_test_copy[stochastic_model+'_MNN_price']+yearwise_data_test_copy[stochastic_model] \n",
    "            yearwise_data_test_copy[stochastic_model+'_MNN_square_error'] = ((yearwise_data_test['last']-yearwise_data_test_copy[stochastic_model+'_MNN_price'])/yearwise_data_test['last'])**2\n",
    "            \n",
    "            years_performance.append(yearwise_data_test_copy[stochastic_model+'_MNN_square_error'].mean()) \n",
    "            years_data = years_data.append(yearwise_data_test_copy) \n",
    "        \n",
    "        elif inverse_transform == True: # fit_transform on target for later inverse_transform\n",
    "            history = model.fit(sc1.fit_transform(yearwise_data_train[['moneyness','tau']]),sc2.fit_transform(yearwise_data_train[['minus']]),batch_size=50,epochs=100,verbose=2, validation_data=(sc3.fit_transform(yearwise_data_validation[['moneyness','tau']]),sc3.fit_transform(yearwise_data_validation[['minus']])),callbacks=[es])\n",
    "            \n",
    "            # percentage mean-squared-error:    \n",
    "            prediction = model.predict(sc1.transform(yearwise_data_test[['moneyness','tau']]))\n",
    "            yearwise_data_test_copy = yearwise_data_test.copy()\n",
    "            yearwise_data_test_copy[stochastic_model+'_MNN_price'] = sc2.inverse_transform(prediction)  # inverse transform\n",
    "            yearwise_data_test_copy[stochastic_model+'_MNN_price']=yearwise_data_test_copy[stochastic_model+'_MNN_price']+yearwise_data_test_copy[stochastic_model]\n",
    "            yearwise_data_test_copy[stochastic_model+'_MNN_square_error'] = ((yearwise_data_test['last']-yearwise_data_test_copy[stochastic_model+'_MNN_price'])/yearwise_data_test['last'])**2\n",
    "            \n",
    "            years_performance.append(yearwise_data_test_copy[stochastic_model+'_MNN_square_error'].mean())\n",
    "            years_data = years_data.append(yearwise_data_test_copy) \n",
    "        \n",
    "    # aggregete\n",
    "    performance.append(years_performance)\n",
    "    output_df = output_df.append(years_data)\n",
    "    print('percentage mean square error of',tau_class,moneyness_class,'call:',np.mean(years_performance))\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# container\n",
    "performance = []\n",
    "VG_MNN_output = pd.DataFrame()   \n",
    "Heston_MNN_output = pd.DataFrame()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "VG_MNN_output = hybrid_MNN_pricing(call_option,'itm','shortterm',[10,5,1],['selu','relu','linear'],False,VG_MNN_output,stochastic_model='VG_price')\n",
    "VG_MNN_output = hybrid_MNN_pricing(call_option,'itm','midterm',[10,5,1],['selu','relu','linear'],False,VG_MNN_output,stochastic_model='VG_price')\n",
    "VG_MNN_output = hybrid_MNN_pricing(call_option,'itm','longterm',[10,5,1],['selu','relu','linear'],False,VG_MNN_output,stochastic_model='VG_price')\n",
    "VG_MNN_output = hybrid_MNN_pricing(call_option,'atm','shortterm',[10,5,1],['relu','relu','linear'],False,VG_MNN_output,stochastic_model='VG_price')\n",
    "VG_MNN_output = hybrid_MNN_pricing(call_option,'atm','midterm',[10,5,1],['relu','relu','linear'],False,VG_MNN_output,stochastic_model='VG_price')\n",
    "VG_MNN_output = hybrid_MNN_pricing(call_option,'atm','longterm',[10,5,1],['relu','relu','linear'],False,VG_MNN_output,stochastic_model='VG_price')\n",
    "VG_MNN_output = hybrid_MNN_pricing(call_option,'otm','shortterm',[10,5,1],['relu','relu','linear'],False,VG_MNN_output,stochastic_model='VG_price')\n",
    "VG_MNN_output = hybrid_MNN_pricing(call_option,'otm','midterm',[10,5,1],['relu','relu','linear'],False,VG_MNN_output,stochastic_model='VG_price')\n",
    "VG_MNN_output = hybrid_MNN_pricing(call_option,'otm','longterm',[10,5,1],['relu','relu','linear'],False,VG_MNN_output,stochastic_model='VG_price')\n",
    "\n",
    "Heston_MNN_output = hybrid_MNN_pricing(call_option,'itm','shortterm',[10,5,1],['selu','relu','linear'],False,Heston_MNN_output,stochastic_model='heston_price')\n",
    "Heston_MNN_output = hybrid_MNN_pricing(call_option,'itm','midterm',[10,5,1],['selu','relu','linear'],False,Heston_MNN_output,stochastic_model='heston_price')\n",
    "Heston_MNN_output = hybrid_MNN_pricing(call_option,'itm','longterm',[10,5,1],['selu','relu','linear'],False,Heston_MNN_output,stochastic_model='heston_price')\n",
    "Heston_MNN_output = hybrid_MNN_pricing(call_option,'atm','shortterm',[10,5,1],['relu','relu','linear'],False,Heston_MNN_output,stochastic_model='heston_price')\n",
    "Heston_MNN_output = hybrid_MNN_pricing(call_option,'atm','midterm',[10,5,1],['relu','relu','linear'],False,Heston_MNN_output,stochastic_model='heston_price')\n",
    "Heston_MNN_output = hybrid_MNN_pricing(call_option,'atm','longterm',[10,5,1],['relu','relu','linear'],False,Heston_MNN_output,stochastic_model='heston_price')\n",
    "Heston_MNN_output = hybrid_MNN_pricing(call_option,'otm','shortterm',[10,5,1],['relu','relu','linear'],False,Heston_MNN_output,stochastic_model='heston_price')\n",
    "Heston_MNN_output = hybrid_MNN_pricing(call_option,'otm','midterm',[10,5,1],['relu','relu','linear'],False,Heston_MNN_output,stochastic_model='heston_price')\n",
    "Heston_MNN_output = hybrid_MNN_pricing(call_option,'otm','longterm',[10,5,1],['relu','relu','linear'],False,Heston_MNN_output,stochastic_model='heston_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge\n",
    "option = option.merge(VG_MNN_output,how = 'left')\n",
    "option = option.merge(Heston_MNN_output,how = 'left')\n",
    "option.to_pickle('hybrid_MNN.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 tf",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
